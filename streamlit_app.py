import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import akshare as ak
import pandas as pd
import re
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv

load_dotenv()

st.set_page_config(page_title="AI çƒ­ç‚¹ä¸ªè‚¡ç ”åˆ¤ç»ˆç«¯", layout="wide")

# ================= å…¨é‡å…³é”®è¯ï¼ˆä½ æä¾›çš„ + è¡¥å……ï¼‰=================
KEYWORDS = [
    # AI & ç®—åŠ›
    "AI", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "GLM", "GLM-Image", "æ™ºè°±", "æ˜‡è…¾", "Atlas", "MindSpore",
    "ç®—åŠ›", "GPU", "NPU", "AIèŠ¯ç‰‡", "å¯’æ­¦çºª", "æµ·å…‰ä¿¡æ¯", "å£ä»", "å¤©æ•°", "ç‡§åŸ",
    "AIæœåŠ¡å™¨", "è®­ç»ƒé›†ç¾¤", "æ¨ç†", "å›½äº§ç®—åŠ›", "å…¨æ ˆè‡ªä¸»", "SOTA", "Hugging Face",
    
    # åŠå¯¼ä½“
    "åŠå¯¼ä½“", "èŠ¯ç‰‡", "å…‰åˆ»æœº", "ASML", "ä¸­èŠ¯å›½é™…", "åè™¹", "åä¸ºæµ·æ€", "é•¿æ±Ÿå­˜å‚¨", "é•¿é‘«å­˜å‚¨",
    "å…ˆè¿›å°è£…", "Chiplet", "HBM", "EDA", "Synopsys", "Cadence", "åå¤§ä¹å¤©", "æ¦‚ä¼¦ç”µå­",
    "æ™¶åœ†", "è®¾å¤‡", "ææ–™", "åˆ»èš€", "è–„è†œ", "ç¦»å­æ³¨å…¥", "åŒ—æ–¹ååˆ›", "ä¸­å¾®å…¬å¸", "æ‹“è†ç§‘æŠ€", "ç››ç¾ä¸Šæµ·",
    
    # å…‰é€šä¿¡
    "å…‰æ¨¡å—", "CPO", "800G", "1.6T", "LPO", "ç¡…å…‰", "Coherent", "æ–°æ˜“ç››", "ä¸­é™…æ—­åˆ›", "å¤©å­šé€šä¿¡",
    
    # æ–°èƒ½æº
    "å…‰ä¼", "é£ç”µ", "æ°¢èƒ½", "å‚¨èƒ½", "é”‚ç”µæ± ", "å›ºæ€ç”µæ± ", "é’ ç¦»å­", "å®å¾·æ—¶ä»£", "æ¯”äºšè¿ª", "äº¿çº¬é”‚èƒ½",
    "éš†åŸº", "é€šå¨", "æ™¶ç§‘", "é€†å˜å™¨", "HJT", "TOPCon", "é’™é’›çŸ¿", "BCç”µæ± ",
    
    # æ–°ææ–™
    "ç»çº¤", "ä½ä»‹ç”µ", "è¦†é“œæ¿", "PCB", "èŠ³çº¶", "PIè†œ", "ç¢³çº¤ç»´", "ç¨€åœŸ", "é«˜æ¸©åˆé‡‘", "è¶…å¯¼",
    
    # æ•°å­—ç»æµ
    "5G", "6G", "å«æ˜Ÿäº’è”ç½‘", "ä¸œæ•°è¥¿ç®—", "ä¿¡åˆ›", "å›½äº§æ›¿ä»£", "æ“ä½œç³»ç»Ÿ", "æ•°æ®åº“",
    "åä¸ºæ¬§æ‹‰", "openGauss", "è¾¾æ¢¦", "äººå¤§é‡‘ä»“", "éº’éºŸè½¯ä»¶",
    
    # æ”¿ç­–ä¸ä¸»é¢˜
    "æ–°è´¨ç”Ÿäº§åŠ›", "è®¾å¤‡æ›´æ–°", "ä»¥æ—§æ¢æ–°", "ä¸“ç²¾ç‰¹æ–°", "å°å·¨äºº", "ç§‘åˆ›æ¿", "åŒ—äº¤æ‰€",
    "å¹¶è´­é‡ç»„", "å›è´­", "å¢æŒ", "å‡æŒ", "å®šå¢", "è‚¡æƒæ¿€åŠ±",
    
    # å¸‚åœºæƒ…ç»ªä¸åšå¼ˆ
    "å‡»é¼“ä¼ èŠ±", "æ¥ç›˜", "æ¸¸èµ„", "æœºæ„", "é‡åŒ–", "æ•£æˆ·", "é¾™è™æ¦œ", "æ¶¨åœ", "è¿æ¿", "æ–­æ¿",
    "é¢„æœŸå·®", "å…‘ç°", "åˆ©å¥½å‡ºå°½", "åˆ†æ­§", "ä¸€è‡´", "é«˜æ½®", "é€€æ½®", "å¡ä½", "é€ æ¢¦", "æ•…äº‹",
    "è½åœ°æ€§", "è®¢å•éªŒè¯", "é‡äº§", "è‰¯ç‡", "æ¯›åˆ©ç‡", "å‡€åˆ©ç‡",
    
    # å®è§‚ç»æµ
    "é™æ¯", "é™å‡†", "CPI", "PPI", "ç¤¾è", "PMI", "ç¾è”å‚¨", "äººæ°‘å¸", "å›½å€º", "æ±‡ç‡",
    
    # å‰æ²¿ç§‘æŠ€
    "ä½ç©ºç»æµ", "eVTOL", "é£è¡Œæ±½è½¦", "äº¿èˆª", "å°é¹æ±‡å¤©", "å³°é£",
    "å•†ä¸šèˆªå¤©", "ç«ç®­", "å«æ˜Ÿ", "é“¶æ²³èˆªå¤©", "æ—¶ç©ºé“å®‡",
    "è„‘æœºæ¥å£", "Neuralink", "ä¾µå…¥å¼", "éä¾µå…¥å¼",
    "é‡å­è®¡ç®—", "é‡å­é€šä¿¡", "æœ¬æºé‡å­", "å›½ç›¾é‡å­",
    "äººå½¢æœºå™¨äºº", "å…·èº«æ™ºèƒ½", "ç‰¹æ–¯æ‹‰Optimus", "å®‡æ ‘", "ä¼˜å¿…é€‰"
]

# ================= è·å– AkShare æ–°é—»ï¼ˆè‡ªåŠ¨æŠ“å–ï¼Œè¿‘5å¤©ï¼‰=================
@st.cache_data(ttl=600)
def fetch_akshare_news():
    try:
        df = ak.stock_news_em(symbol="å…¨éƒ¨")
        if df.empty:
            return pd.DataFrame()
        df['æ—¶é—´æˆ³'] = pd.to_datetime(df['å‘å¸ƒæ—¶é—´'], errors='coerce')
        df = df.dropna(subset=['æ—¶é—´æˆ³'])
        df['å‘å¸ƒæ—¥æœŸ'] = df['æ—¶é—´æˆ³'].dt.strftime('%Y-%m-%d')
        df['å‘å¸ƒæ—¶é—´'] = df['æ—¶é—´æˆ³'].dt.strftime('%H:%M')
        df = df.rename(columns={'æ–°é—»æ ‡é¢˜': 'æ ‡é¢˜', 'æ–°é—»å†…å®¹': 'å†…å®¹'})
        # ä»…ä¿ç•™æœ€è¿‘5å¤©æ–°é—»
        cutoff = datetime.now() - timedelta(days=5)
        df = df[df['æ—¶é—´æˆ³'] >= cutoff]
        df = df.sort_values('æ—¶é—´æˆ³', ascending=False).reset_index(drop=True)
        return df[['æ ‡é¢˜', 'å†…å®¹', 'å‘å¸ƒæ—¥æœŸ', 'å‘å¸ƒæ—¶é—´']].head(50)
    except Exception as e:
        st.error(f"AkShare è·å–å¤±è´¥: {e}")
        return pd.DataFrame()

# ================= ä¸»åº”ç”¨ =================
def main():
    st.title("ğŸ” AI çƒ­ç‚¹ä¸ªè‚¡ç ”åˆ¤ç»ˆç«¯")

    # === é¡¶éƒ¨å…³é”®è¯æœç´¢æ¡† ===
    user_keywords = st.text_input(
        "ğŸ” è¾“å…¥å…³é”®è¯ï¼ˆå¦‚ï¼šä½ç©ºç»æµ, æ˜‡è…¾, è®¾å¤‡æ›´æ–°ï¼‰",
        placeholder="æ”¯æŒå¤šä¸ªå…³é”®è¯ï¼Œç”¨ä¸­æ–‡é€—å·æˆ–ç©ºæ ¼åˆ†éš”",
        key="keyword_input"
    )

    api_key = os.getenv("ZHIPU_API_KEY")
    if not api_key:
        st.error("âŒ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® ZHIPU_API_KEY")
        return

    # === è·å–åŸå§‹æ–°é—» ===
    raw_news_df = fetch_akshare_news()
    if raw_news_df.empty:
        st.warning("æš‚æ— æ–°é—»æ•°æ®ï¼Œè¯·ç¨åå†è¯•ã€‚")
        return

    # === å¤„ç†å…³é”®è¯è¿‡æ»¤ ===
    filtered_news = raw_news_df.copy()
    keywords_list = []
    if user_keywords.strip():
        # åˆ†å‰²å…³é”®è¯ï¼ˆæ”¯æŒä¸­æ–‡é€—å·ã€è‹±æ–‡é€—å·ã€ç©ºæ ¼ï¼‰
        keywords_list = [kw.strip() for kw in re.split(r'[,\sï¼Œ]+', user_keywords.strip()) if kw.strip()]
        if keywords_list:
            def contains_keyword(text):
                return any(kw in text for kw in keywords_list)
            mask = filtered_news['æ ‡é¢˜'].apply(contains_keyword) | filtered_news['å†…å®¹'].apply(contains_keyword)
            filtered_news = filtered_news[mask].reset_index(drop=True)

    if filtered_news.empty:
        st.info("æœªæ‰¾åˆ°åŒ¹é…å…³é”®è¯çš„æ–°é—»ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯ã€‚")
        return

    # === çŠ¶æ€ç®¡ç† ===
    if 'selected_idx' not in st.session_state:
        st.session_state.selected_idx = 0
        st.session_state.analysis_cache = {}

    col_list, col_detail = st.columns([2.8, 7.2])

    with col_list:
        st.subheader(f"ğŸ“° æ–°é—»åˆ—è¡¨ï¼ˆå…± {len(filtered_news)} æ¡ï¼‰")
        if keywords_list:
            st.caption(f"å…³é”®è¯ï¼š{'ã€'.join(keywords_list)}")
        for idx, row in filtered_news.iterrows():
            is_selected = idx == st.session_state.selected_idx
            if st.button(
                f"**{row['æ ‡é¢˜']}**\n`{row['å‘å¸ƒæ—¥æœŸ']} {row['å‘å¸ƒæ—¶é—´']}`",
                key=f"news_{idx}",
                type="primary" if is_selected else "secondary",
                use_container_width=True
            ):
                st.session_state.selected_idx = idx
                st.rerun()

    with col_detail:
        current = filtered_news.iloc[st.session_state.selected_idx]
        cache_key = f"{current['æ ‡é¢˜']}|{user_keywords}"

        # æ˜¾ç¤ºæ–°é—»è¯¦æƒ…
        st.markdown("### ğŸ“Œ æ–°é—»è¯¦æƒ…")
        st.caption(f"{current['å‘å¸ƒæ—¥æœŸ']} {current['å‘å¸ƒæ—¶é—´']}")
        
        # é«˜äº®å…³é”®è¯
        content_display = current['å†…å®¹']
        if keywords_list:
            for kw in keywords_list:
                content_display = re.sub(
                    f"({re.escape(kw)})",
                    r"<mark style='background:#fffacd;font-weight:bold'>\1</mark>",
                    content_display,
                    flags=re.IGNORECASE
                )
        
        st.markdown(
            f"<div style='background:#f9fafb;padding:14px;border-radius:10px;margin-bottom:24px;'>{content_display}</div>",
            unsafe_allow_html=True
        )

        # ç¼“å­˜åˆ†æç»“æœ
        if cache_key not in st.session_state.analysis_cache:
            with st.spinner("ğŸ§  AI æ­£åœ¨åˆ†æå—ç›Šè‚¡åŠä¸‰ç»´åº¦é˜¶æ®µ..."):
                try:
                    llm = ChatOpenAI(
                        api_key=api_key,
                        base_url="https://open.bigmodel.cn/api/paas/v4/",
                        model="glm-4",
                        temperature=0.2
                    )
                    prompt = ChatPromptTemplate.from_messages([
                        ("system",
                         "ä½ æ˜¯é¡¶çº§äº§ä¸šèµ„æœ¬æ“ç›˜æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ­¥éª¤å¤„ç†ï¼š\n\n"
                         "1ï¸âƒ£ **å…ˆåˆ—å‡º 2-4 åªæœ€ç›´æ¥å—ç›Šçš„ A è‚¡**ï¼Œæ ¼å¼å¿…é¡»ä¸ºï¼š**å…¬å¸å…¨ç§°ï¼ˆ6ä½æ•°å­—ä»£ç ï¼‰**\n"
                         "   - å¿…é¡»æ˜¯çœŸå®å­˜åœ¨çš„ A è‚¡ï¼ˆä»£ç ä»¥ 00/30/60/68 å¼€å¤´ï¼‰\n"
                         "   - ç¦æ­¢è™šæ„å…¬å¸æˆ–ä½¿ç”¨æ¸¯è‚¡/ç¾è‚¡ä»£ç \n\n"
                         "2ï¸âƒ£ **å¯¹æ¯åªè‚¡ç¥¨ï¼Œåˆ†åˆ«è¿›è¡Œä¸‰ç»´åº¦ç ”åˆ¤**ï¼š\n"
                         "   - **å¡ä½**ï¼šæ˜¯å¦çœŸå®å¡ä½ï¼Ÿæœ‰æ— æŠ€æœ¯/è®¢å•/æ”¿ç­–å£å’ï¼Ÿæ˜¯å¦è¹­æ¦‚å¿µï¼Ÿ\n"
                         "   - **é¢„æœŸå·®**ï¼šå½“å‰å¸‚åœºé¢„æœŸ vs æ½œåœ¨ç©ºé—´ï¼ˆå¯ç”¨%ä¼°ç®—ï¼‰ï¼Œæ˜¯å¦å­˜åœ¨è®¤çŸ¥å·®ï¼Ÿ\n"
                         "   - **å‡»é¼“ä¼ èŠ±é˜¶æ®µ**ï¼šå¯åŠ¨ / åŠ é€Ÿ / é«˜æ½® / é€€æ½®ï¼Ÿä¸»å¯¼èµ„é‡‘æ˜¯è°ï¼ˆæ¸¸èµ„/æœºæ„/æ•£æˆ·ï¼‰ï¼Ÿ\n\n"
                         "3ï¸âƒ£ è¯­è¨€çŠ€åˆ©ã€æ•°æ®åŒ–ï¼Œç¦æ­¢æ¨¡ç³Šè¯ã€‚"
                        ),
                        ("user", f"æ–°é—»æ ‡é¢˜ï¼š{current['æ ‡é¢˜']}\n\næ–°é—»å†…å®¹ï¼š{current['å†…å®¹']}")
                    ])
                    result = (prompt | llm | StrOutputParser()).invoke({})
                    st.session_state.analysis_cache[cache_key] = result
                except Exception as e:
                    st.session_state.analysis_cache[cache_key] = f"âŒ åˆ†æå¤±è´¥ï¼š{str(e)}"

        # æ˜¾ç¤º AI åˆ†æç»“æœ
        st.markdown("### ğŸ” AI åŠ¨æ€ç ”åˆ¤ç»“æœ")
        st.markdown(st.session_state.analysis_cache[cache_key])

if __name__ == "__main__":
    main()
